{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science - Poster Workshop\n",
    "# How can we analyze data in order to discover new insights that are eventually in?\n",
    "\n",
    "We are using the Yeast dataset from:     \n",
    "\n",
    "    Kenta Nakai\n",
    "    Institue of Molecular and Cellular Biology\n",
    "\tOsaka, University\n",
    "\t1-3 Yamada-oka, Suita 565 Japan\n",
    "    nakai@imcb.osaka-u.ac.jp\n",
    "    http://www.imcb.osaka-u.ac.jp/nakai/psort.html\n",
    "    Donor: Paul Horton (paulh@cs.berkeley.edu)\n",
    "    Date:  September, 1996\n",
    "    See also: ecoli database\n",
    "\n",
    "This dataset is available here in the [UCI Archive](https://archive.ics.uci.edu/dataset/110/yeast)\n",
    "\n",
    "For this data science poster workshop we will be seeing different ways of classifying the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the poster workshop specifications\n",
    "\n",
    "- The pw is organised at the end of the semester. The pw is based on the presentation of project.\n",
    "- A student can participate individually or as a member of a group of up to 3 students and thus take part in the project.\n",
    "- A project is defined as a performance in the sense of data science on a data set that is provided. Possibly, 2 or 3 data sets will be presented and each group can choose 1 of them.\n",
    "- The project work consists of demonstrating an aspect of the course using the selected dataset. The terminology must be used.\n",
    "- The PW is divided into two parts: \n",
    "\n",
    "    - Part 1 is an \"appetiser\" presentation in which the most important aspects of the project are presented (5 minutes). The aim is to promote own work and convince examiners to come and get more information\n",
    "    - In Part 2, each student/group hangs a poster on the wall and explains the work to the examiners.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1484 entries, 0 to 1483\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Sequence_Name      1484 non-null   object \n",
      " 1   mcg                1484 non-null   float64\n",
      " 2   gvh                1484 non-null   float64\n",
      " 3   alm                1484 non-null   float64\n",
      " 4   mit                1484 non-null   float64\n",
      " 5   erl                1484 non-null   float64\n",
      " 6   pox                1484 non-null   float64\n",
      " 7   vac                1484 non-null   float64\n",
      " 8   nuc                1484 non-null   float64\n",
      " 9   localization_site  1484 non-null   object \n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 116.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"yeast/yeast.data\", header=None, sep='\\s+', engine='python')\n",
    "\n",
    "df.columns = [\"Sequence_Name\", \"mcg\", \"gvh\", \"alm\", \"mit\", \"erl\", \"pox\", \"vac\", \"nuc\", \"localization_site\"]\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this poster is to predict our target \"localization_site\" based on the 8 features given.\n",
    "\n",
    "We will perform classification on using multiple different models and evaluate the performance of each model based on its accuracy and precision.\n",
    "\n",
    "Finaly we will look at overall insights we can draw from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localization_site\n",
      "CYT    463\n",
      "NUC    429\n",
      "MIT    244\n",
      "ME3    163\n",
      "ME2     51\n",
      "ME1     44\n",
      "EXC     35\n",
      "VAC     30\n",
      "POX     20\n",
      "ERL      5\n",
      "Name: count, dtype: int64\n",
      "Index(['CYT', 'ERL', 'EXC', 'ME1', 'ME2', 'ME3', 'MIT', 'NUC', 'POX', 'VAC'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The number of different occurences for each localization sites\n",
    "print(df['localization_site'].value_counts())\n",
    "\n",
    "# Setup localization_site as a category\n",
    "df[\"localization_site\"] = df[\"localization_site\"].astype('category')\n",
    "\n",
    "print(df[\"localization_site\"].cat.categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
